{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def sampleData(inputFile, outputFile, targetSize, filterKey='also_buy'):\n",
    "    targetSize = targetSize * 1024 * 1024 * 1024\n",
    "    currentSize = 0\n",
    "\n",
    "    with open(inputFile, 'r', encoding='utf-8') as input, open(outputFile, 'w', encoding='utf-8') as output:\n",
    "        for line in tqdm(input):\n",
    "            data = json.loads(line)\n",
    "            if data.get(filterKey):\n",
    "                output.write(json.dumps(data) + '\\n')\n",
    "                currentSize += len(line.encode('utf-8'))\n",
    "\n",
    "            if currentSize >= targetSize:\n",
    "                break\n",
    "\n",
    "sampleData('Sample_Amazon_Meta3.json', 'Sample_Amazon_Meta33.json', 0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def preprocessing(inputFile, outputFile):\n",
    "    with open(inputFile, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "\n",
    "            # Preprocess feature field\n",
    "            feature = data.get('feature', [])\n",
    "            featureCleaned = ' '.join(feature).lower()\n",
    "            featureCleaned = re.sub(r'[\\d\\W_ ]+', '', featureCleaned)\n",
    "\n",
    "            # Preprocess description field\n",
    "            description = data.get('description', [])\n",
    "            descriptionCleaned = ' '.join(description).lower()\n",
    "            descriptionCleaned = re.sub(r'[\\d\\W_ ]+', '', descriptionCleaned)\n",
    "\n",
    "            # Print original and preprocessed data\n",
    "            print(\"Original Feature:\", feature)\n",
    "            print(\"Preprocessed Feature:\", featureCleaned)\n",
    "            print(\"Original Description:\", description)\n",
    "            print(\"Preprocessed Description:\", descriptionCleaned)\n",
    "\n",
    "            # Update the data dictionary\n",
    "            data['feature'] = featureCleaned\n",
    "            data['description'] = descriptionCleaned\n",
    "\n",
    "            # Write the preprocessed data to the output file\n",
    "            with open(outputFile, 'a', encoding='utf-8') as outputFilee:\n",
    "                outputFilee.write(json.dumps(data) + '\\n')\n",
    "\n",
    "preprocessing('Sample_Amazon_Meta.json', 'Preprocessed_Amazon_Meta.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json \n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove digits, special characters, and underscores\n",
    "    cleaned_text = re.sub(r'[\\d\\W_]+', ' ', text)\n",
    "    # Convert to lowercase\n",
    "    cleaned_text = cleaned_text.lower()\n",
    "    return cleaned_text.strip()\n",
    "\n",
    "def preprocessing(inputFile, outputFile):\n",
    "    processedData = []\n",
    "\n",
    "    with open(inputFile, 'r', encoding='utf-8') as inputFilee:\n",
    "        # Count the total number of lines in the input file for tqdm progress tracking\n",
    "        total_lines = sum(1 for _ in open(inputFile, 'r', encoding='utf-8'))\n",
    "\n",
    "        with tqdm(total=total_lines, desc='Processing Data') as pbar:\n",
    "            for line in inputFilee:\n",
    "                try:\n",
    "                    data = json.loads(line)\n",
    "\n",
    "                    title = preprocess_text(data.get('title', ''))\n",
    "                    feature = preprocess_text(data.get('feature', ''))\n",
    "                    description = preprocess_text(data.get('description', ''))\n",
    "                    brand = preprocess_text(data.get('brand', ''))\n",
    "\n",
    "                    # Exclude categories column from preprocessing\n",
    "                    # If 'categories' is in data, you can skip it as follows\n",
    "                    categories = data.get('categories', '')\n",
    "\n",
    "                    # Create a transaction with preprocessed data\n",
    "                    transaction = {\n",
    "                        'title': title,\n",
    "                        'feature': feature,\n",
    "                        'description': description,\n",
    "                        'brand': brand,\n",
    "                        'categories': categories,  # Include 'categories' as-is\n",
    "                        'related': data.get('related', {})  # Include 'related' as-is\n",
    "                    }\n",
    "                    print(\"Preprocessed data:\", transaction)  # Print the preprocessed data\n",
    "                    processedData.append(transaction)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing line: {line}\")\n",
    "                    print(e)\n",
    "\n",
    "                # Update tqdm progress bar\n",
    "                pbar.update(1)\n",
    "\n",
    "    with open(outputFile, 'w', encoding='utf-8') as outputFilee:\n",
    "        for item in processedData:\n",
    "            outputFilee.write(json.dumps(item) + '\\n')\n",
    "\n",
    "preprocessing('Sample_Amazon_Meta3.json', 'Preprocessed_Amazon_Meta2.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
