{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54093it [00:04, 11735.30it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def sampleData(inputFile, outputFile, targetSize, filterKey='also_buy'):\n",
    "    targetSize = targetSize * 1024 * 1024 * 1024\n",
    "    currentSize = 0\n",
    "\n",
    "    with open(inputFile, 'r', encoding='utf-8') as input, open(outputFile, 'w', encoding='utf-8') as output:\n",
    "        for line in tqdm(input):\n",
    "            data = json.loads(line)\n",
    "            if data.get(filterKey):\n",
    "                output.write(json.dumps(data) + '\\n')\n",
    "                currentSize += len(line.encode('utf-8'))\n",
    "\n",
    "            if currentSize >= targetSize:\n",
    "                break\n",
    "\n",
    "sampleData('Sampled_Amazon_Meta.json', 'Sample_Amazon_Meta3.json', 0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json \n",
    "# import re\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# def preprocessing(inputFile, outputFile):\n",
    "#     processedData = []\n",
    "\n",
    "#     with open(inputFile, 'r', encoding='utf-8') as inputFilee:\n",
    "#         # Count the total number of lines in the input file for tqdm progress tracking\n",
    "#         total_lines = sum(1 for _ in open(inputFile, 'r', encoding='utf-8'))\n",
    "\n",
    "#         with tqdm(total=total_lines, desc='Processing Data') as pbar:\n",
    "#             for line in inputFilee:\n",
    "#                 data = json.loads(line)\n",
    "\n",
    "#                 if 'title' in data and 'related' in data and 'also_bought' in data['related']:\n",
    "#                     title = data.get('title', '')\n",
    "#                     titleCleaned = re.sub(r'[\\d\\W_ ]+', '', title).lower()\n",
    "\n",
    "#                     # Preprocess other fields if needed\n",
    "#                     feature = data.get('feature', '')\n",
    "#                     featureCleaned = re.sub(r'[\\d\\W_ ]+', '', feature).lower()\n",
    "\n",
    "#                     description = data.get('description', '')\n",
    "#                     descriptionCleaned = re.sub(r'[\\d\\W_ ]+', '', description).lower()\n",
    "\n",
    "#                     brand = data.get('brand', '')\n",
    "#                     brandCleaned = re.sub(r'[\\d\\W_ ]+', '', brand).lower()\n",
    "\n",
    "#                     # Create a transaction with preprocessed data\n",
    "#                     transaction = {\n",
    "#                         'title': titleCleaned,\n",
    "#                         'feature': featureCleaned,\n",
    "#                         'description': descriptionCleaned,\n",
    "#                         'brand': brandCleaned,\n",
    "#                         'related': data['related']['also_bought']\n",
    "#                     }\n",
    "#                     processedData.append(transaction)\n",
    "\n",
    "#                 # Update tqdm progress bar\n",
    "#                 pbar.update(1)\n",
    "\n",
    "#     with open(outputFile, 'w', encoding='utf-8') as outputFilee:\n",
    "#         for item in processedData:\n",
    "#             outputFilee.write(json.dumps(item) + '\\n')\n",
    "\n",
    "# preprocessing('Sample_Amazon_Meta2.json', 'Preprocessed_Amazon_Meta222.json')\n",
    "\n",
    "import json \n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove digits, special characters, and underscores\n",
    "    cleaned_text = re.sub(r'[\\d\\W_]+', ' ', text)\n",
    "    # Convert to lowercase\n",
    "    cleaned_text = cleaned_text.lower()\n",
    "    return cleaned_text.strip()\n",
    "\n",
    "def preprocessing(inputFile, outputFile):\n",
    "    processedData = []\n",
    "\n",
    "    with open(inputFile, 'r', encoding='utf-8') as inputFilee:\n",
    "        # Count the total number of lines in the input file for tqdm progress tracking\n",
    "        total_lines = sum(1 for _ in open(inputFile, 'r', encoding='utf-8'))\n",
    "\n",
    "        with tqdm(total=total_lines, desc='Processing Data') as pbar:\n",
    "            for line in inputFilee:\n",
    "                try:\n",
    "                    data = json.loads(line)\n",
    "\n",
    "                    title = preprocess_text(data.get('title', ''))\n",
    "                    feature = preprocess_text(data.get('feature', ''))\n",
    "                    description = preprocess_text(data.get('description', ''))\n",
    "                    brand = preprocess_text(data.get('brand', ''))\n",
    "\n",
    "                    # Exclude categories column from preprocessing\n",
    "                    # If 'categories' is in data, you can skip it as follows\n",
    "                    categories = data.get('categories', '')\n",
    "\n",
    "                    # Create a transaction with preprocessed data\n",
    "                    transaction = {\n",
    "                        'title': title,\n",
    "                        'feature': feature,\n",
    "                        'description': description,\n",
    "                        'brand': brand,\n",
    "                        'categories': categories,  # Include 'categories' as-is\n",
    "                        'related': data.get('related', {})  # Include 'related' as-is\n",
    "                    }\n",
    "                    print(\"Preprocessed data:\", transaction)  # Print the preprocessed data\n",
    "                    processedData.append(transaction)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing line: {line}\")\n",
    "                    print(e)\n",
    "\n",
    "                # Update tqdm progress bar\n",
    "                pbar.update(1)\n",
    "\n",
    "    with open(outputFile, 'w', encoding='utf-8') as outputFilee:\n",
    "        for item in processedData:\n",
    "            outputFilee.write(json.dumps(item) + '\\n')\n",
    "\n",
    "preprocessing('Sample_Amazon_Meta3.json', 'Preprocessed_Amazon_Meta2.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
